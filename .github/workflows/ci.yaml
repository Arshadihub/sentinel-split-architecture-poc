name: sentinel-poc

on:
  push:
    branches: [ main ]

env:
  TF_WORKING_DIR: terraform/envs/us-east-1

jobs:
  ci-deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.5

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Terraform Init
        run: terraform init
        working-directory: ${{ env.TF_WORKING_DIR }}

      - name: Import CloudWatch Log Groups (before plan)
        run: pwsh ./scripts/import-loggroups.ps1

      - name: Install tflint
        run: |
          curl -sSL https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash

      - name: Run tflint
        run: |
          cd ${{ env.TF_WORKING_DIR }}
          tflint --init || true
          tflint

      - name: Terraform Validate
        run: terraform validate
        working-directory: ${{ env.TF_WORKING_DIR }}

      - name: Terraform Plan
        run: terraform plan -out=tfplan
        working-directory: ${{ env.TF_WORKING_DIR }}

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan
        working-directory: ${{ env.TF_WORKING_DIR }}

      # Import moved earlier to avoid create conflicts

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Install kubeval
        run: |
          curl -sLO https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz
          tar xzf kubeval-linux-amd64.tar.gz
          sudo mv kubeval /usr/local/bin/
          rm kubeval-linux-amd64.tar.gz

      - name: Check EKS nodegroups before K8s deployment
        id: check-nodegroups
        run: |
          BACKEND_NODEGROUPS=$(aws eks list-nodegroups --cluster-name eks-backend --region us-east-1 --query 'length(nodegroups)' --output text)
          GATEWAY_NODEGROUPS=$(aws eks list-nodegroups --cluster-name eks-gateway --region us-east-1 --query 'length(nodegroups)' --output text)
          echo "backend_nodegroups=$BACKEND_NODEGROUPS" >> $GITHUB_OUTPUT
          echo "gateway_nodegroups=$GATEWAY_NODEGROUPS" >> $GITHUB_OUTPUT
          if [ "$BACKEND_NODEGROUPS" -eq "0" ] || [ "$GATEWAY_NODEGROUPS" -eq "0" ]; then
            echo "âš ï¸ EKS clusters have no nodegroups yet"
            echo "ðŸ”´ Skipping K8s deployment until IAM permissions and service quotas are increased"
          fi

      - name: Deploy backend manifests to eks-backend
        if: steps.check-nodegroups.outputs.backend_nodegroups != '0'
        run: |
          BACKEND_SG=$(terraform -chdir=${{ env.TF_WORKING_DIR }} output -raw backend_lb_sg_id || true)
          aws eks update-kubeconfig --name eks-backend --region us-east-1
          kubeval k8s/backend/namespace.yaml k8s/backend/deployment.yaml k8s/backend/service.yaml k8s/backend/networkpolicy.yaml || true
          kubectl apply --dry-run=client -f k8s/backend/namespace.yaml
          kubectl apply --dry-run=client -f k8s/backend/deployment.yaml
          kubectl apply --dry-run=client -f k8s/backend/service.yaml
          kubectl apply --dry-run=client -f k8s/backend/networkpolicy.yaml
          kubectl apply -f k8s/backend/namespace.yaml
          kubectl apply -f k8s/backend/deployment.yaml
          if [ -n "$BACKEND_SG" ]; then
            sed "s|__BACKEND_SG__|$BACKEND_SG|g" k8s/backend/service.yaml | kubectl apply -f -
          else
            kubectl apply -f k8s/backend/service.yaml
          fi
          kubectl apply -f k8s/backend/networkpolicy.yaml

      - name: Wait for backend LoadBalancer
        if: steps.check-nodegroups.outputs.backend_nodegroups != '0'
        run: |
          for i in {1..30}; do
            HOST=$(kubectl -n sentinel get svc backend-svc -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' || true)
            if [ -n "$HOST" ]; then echo "LB=$HOST" && break; fi
            sleep 10
          done
          echo "BACKEND_LB=$HOST" >> $GITHUB_ENV

      - name: Deploy gateway manifests to eks-gateway (patch config with backend LB)
        if: steps.check-nodegroups.outputs.gateway_nodegroups != '0' && steps.check-nodegroups.outputs.backend_nodegroups != '0'
        run: |
          aws eks update-kubeconfig --name eks-gateway --region us-east-1
          kubectl apply -f k8s/gateway/namespace.yaml
          cat > nginx.conf <<EOF
          events {}
          http {
            upstream backend {
              server ${BACKEND_LB}:8080;
            }
            server {
              listen 80;
              location / {
                proxy_pass http://backend;
              }
            }
          }
          EOF
          kubectl -n gateway create configmap proxy-conf --from-file=nginx.conf --dry-run=client -o yaml | kubectl apply -f -
          kubectl apply -f k8s/gateway/deployment.yaml
          kubectl apply -f k8s/gateway/service.yaml
